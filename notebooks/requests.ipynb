{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import json\n",
    "import requests\n",
    "\n",
    "# Flow of messages are defiend as segments in this system.\n",
    "# Segments are based on the format of JSON.\n",
    "\n",
    "type segment = list[dict[str, str]]\n",
    "\n",
    "\n",
    "def from_segment_file(filename: str) -> segment:\n",
    "    return json.load(open(filename, \"r\", encoding=\"utf-8\"))\n",
    "\n",
    "\n",
    "def make_segment_file(filename: str, segment: segment) -> None:\n",
    "    return json.dump(\n",
    "        segment,\n",
    "        open(filename, \"w\", encoding=\"utf-8\"),\n",
    "        indent=2,\n",
    "        ensure_ascii=False,\n",
    "    )\n",
    "\n",
    "\n",
    "def to_segment_file(filename: str, segment: segment) -> None:\n",
    "    return make_segment_file(\n",
    "        filename=filename,\n",
    "        segment=from_segment_file(filename=filename) + segment,\n",
    "    )\n",
    "\n",
    "\n",
    "# Messages are categorized as three types usually:\n",
    "# System message, user message and assistant messages.\n",
    "\n",
    "\n",
    "type message = dict[str, str]\n",
    "type message_list = segment\n",
    "\n",
    "\n",
    "def make_message(role: str, content: str) -> message:\n",
    "    return {\n",
    "        \"role\": role,\n",
    "        \"content\": content,\n",
    "    }\n",
    "\n",
    "\n",
    "def make_system_message(content: str) -> message:\n",
    "    return make_message(role=\"system\", content=content)\n",
    "\n",
    "\n",
    "def make_user_message(content: str) -> message:\n",
    "    return make_message(role=\"user\", content=content)\n",
    "\n",
    "\n",
    "def make_assistant_message(content: str) -> message:\n",
    "    return make_message(role=\"assistant\", content=content)\n",
    "\n",
    "\n",
    "# Any request to LLM should be done by a message list.\n",
    "\n",
    "\n",
    "def config_llm(\n",
    "    temperature: Optional[float] = 0.4,\n",
    "    max_tokens: Optional[int] = 512,\n",
    "    max_buffer_tokens: Optional[int] = 1024,\n",
    ") -> dict:\n",
    "    return {\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"max_buffer_tokens\": max_buffer_tokens,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_completion_from_response(response: dict) -> str:\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "\n",
    "\n",
    "def get_prompt_tokens_from_response(response: dict) -> int:\n",
    "    return response[\"usage\"][\"prompt_tokens\"]\n",
    "\n",
    "\n",
    "def get_completion_tokens_from_response(response: dict) -> int:\n",
    "    return response[\"usage\"][\"completion_tokens\"]\n",
    "\n",
    "\n",
    "# def get_response_params(message_list: message_list) -> dict:\n",
    "#     source: str = \"http://localhost:8000/v1/chat/completions\"\n",
    "#     headers: dict = {\n",
    "#         \"accept\": \"application/json\",\n",
    "#         \"Content-Type\": \"application/json\",\n",
    "#     }\n",
    "#     params: dict = {\n",
    "#         \"messages\": message_list,\n",
    "#         \"model\": \"string\",\n",
    "#         \"do_sample\": True,\n",
    "#         \"stream\": False,\n",
    "#         \"max_tokens\": config_llm()[\"max_tokens\"],\n",
    "#         \"temperature\": config_llm()[\"temperature\"],\n",
    "#         \"top_p\": 0,\n",
    "#         \"n\": 1,\n",
    "#     }\n",
    "#     response: dict = requests.post(\n",
    "#         source,\n",
    "#         headers=headers,\n",
    "#         data=json.dumps(params),\n",
    "#     ).json()\n",
    "#     return {\n",
    "#         \"completion\": get_completion_from_response(response),\n",
    "#         \"prompt_tokens\": (prompt_tokens := get_prompt_tokens_from_response(response)),\n",
    "#         \"completion_tokens\": (\n",
    "#             completion_tokens := get_completion_tokens_from_response(response)\n",
    "#         ),\n",
    "#         \"total_tokens\": prompt_tokens + completion_tokens,\n",
    "#     }\n",
    "\n",
    "\n",
    "def get_response_params(message_list: message_list) -> dict:\n",
    "    completion = str([make_system_message(content=\"0123456789\")])\n",
    "    return {\n",
    "        \"completion\": completion,\n",
    "        \"prompt_tokens\": len(str(message_list)),\n",
    "        \"completion_tokens\": len(completion),\n",
    "        \"total_tokens\": len(str(message_list) + completion),\n",
    "    }\n",
    "\n",
    "\n",
    "def get_completion_from_response_params(response_params: dict) -> str:\n",
    "    return response_params[\"completion\"]\n",
    "\n",
    "\n",
    "# It is easy to implement the buffer memory technique from LangChain.\n",
    "\n",
    "\n",
    "def get_total_tokens_from_response_params(message_list: message_list) -> int:\n",
    "    return get_response_params(message_list)[\"total_tokens\"]\n",
    "\n",
    "\n",
    "def is_enough_buffer_tokens(message_list: message_list) -> bool:\n",
    "    return (\n",
    "        get_total_tokens_from_response_params(message_list=message_list)\n",
    "        + config_llm()[\"max_tokens\"]\n",
    "        <= config_llm()[\"max_buffer_tokens\"]\n",
    "    )\n",
    "\n",
    "\n",
    "def process_buffer_message_list(message_list: message_list) -> message_list:\n",
    "    return (\n",
    "        message_list\n",
    "        if is_enough_buffer_tokens(message_list=message_list)\n",
    "        else process_buffer_message_list(message_list=message_list[1:])\n",
    "    )\n",
    "\n",
    "\n",
    "# Since large input length can break the context buffer,\n",
    "# this situation is handled separately.\n",
    "\n",
    "\n",
    "def is_enough_input_length(message_list: message_list) -> bool:\n",
    "    return len(message_list[-1][\"content\"]) <= config_llm()[\"max_tokens\"]\n",
    "\n",
    "\n",
    "def process_buffer(message_list: message_list) -> str:\n",
    "    return (\n",
    "        get_completion_from_response_params(\n",
    "            get_response_params(\n",
    "                message_list=(\n",
    "                    message_list := process_buffer_message_list(\n",
    "                        message_list=message_list,\n",
    "                    )\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        if is_enough_input_length(message_list=message_list)\n",
    "        else \"[ERROR] not enough input length!\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = get_response_params(message_list=[make_user_message(\"Hello\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'completion': \"[{'role': 'system', 'content': '0123456789'}]\",\n",
       " 'prompt_tokens': 38,\n",
       " 'completion_tokens': 45,\n",
       " 'total_tokens': 83}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [make_user_message(\"1234567890\")] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'}]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[{'role': 'system', 'content': '0123456789'}]\""
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = process_buffer(message_list=lst)\n",
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'},\n",
       " {'role': 'user', 'content': '1234567890'}]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_buffer_message_list(message_list=message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_tokens_from_response_params(message_list=message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "475"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_total_tokens_from_response_params(\n",
    "    message_list=process_buffer_message_list(message_list=message_list)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1234567890'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_list[-1][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = [1, 2, 3, 4, 5]\n",
    "lst[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
